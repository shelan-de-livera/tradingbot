{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkZTQpP6tdR1oc4qgJo92M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shelan-de-livera/finalprojecttestrepo/blob/main/test_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5J881nq63rRo",
        "outputId": "0a0c234f-2d28-4782-a912-346b4a904714",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ta\n",
            "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ta) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ta) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->ta) (1.16.0)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=a233584d3d327c30289ddd6a0b6ff1a508b3c30043c1822398d9bc0befd949d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/67/4f/8a9f252836e053e532c6587a3230bc72a4deb16b03a829610b\n",
            "Successfully built ta\n",
            "Installing collected packages: ta\n",
            "Successfully installed ta-0.11.0\n"
          ]
        }
      ],
      "source": [
        "! pip install ta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pytrends"
      ],
      "metadata": {
        "id": "REqU_h0w20kk",
        "outputId": "91bb6463-9cf1-4983-de25-66345d32c402",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytrends\n",
            "  Downloading pytrends-4.9.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.10/dist-packages (from pytrends) (2.31.0)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from pytrends) (1.5.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from pytrends) (4.9.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->pytrends) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->pytrends) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->pytrends) (1.23.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0->pytrends) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0->pytrends) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0->pytrends) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0->pytrends) (2023.7.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.25->pytrends) (1.16.0)\n",
            "Installing collected packages: pytrends\n",
            "Successfully installed pytrends-4.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# database.entities.crypto - crypto.py"
      ],
      "metadata": {
        "id": "qMR-xCDJ26VH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Crypto:\n",
        "    def __init__(self, symbol: str, name: str, start_year: int):\n",
        "        self._symbol = symbol\n",
        "        self._name = name\n",
        "        self._start_year = start_year\n",
        "\n",
        "    @property\n",
        "    def symbol(self) -> str:\n",
        "        return self._symbol\n",
        "\n",
        "    @property\n",
        "    def name(self) -> str:\n",
        "        return self._name\n",
        "\n",
        "    @property\n",
        "    def start_year(self) -> int:\n",
        "        return self._start_year\n",
        "\n"
      ],
      "metadata": {
        "id": "GpZ41y3u20nN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# database.preprocessing.preprocessing - preprocessing.py"
      ],
      "metadata": {
        "id": "pFjFm6X02-U_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "\n",
        "class DatasetPreprocessing(ABC):\n",
        "    @abstractmethod\n",
        "    def preprocess(self, dataset_df: pd.DataFrame) -> pd.DataFrame:\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "RZcY_K3_20p5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# database.preprocessing.gtrends.gtrends - gtrends.py"
      ],
      "metadata": {
        "id": "0HiHSBis3CHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# from database.preprocessing.preprocessing import DatasetPreprocessing\n",
        "\n",
        "\n",
        "class GoogleTrendsPreprocessing(DatasetPreprocessing):\n",
        "    def __init__(\n",
        "            self,\n",
        "            impute_missing_scores: bool = False,\n",
        "            imputing_percentage_threshold: float = 0.1\n",
        "    ):\n",
        "        assert 0.0 < imputing_percentage_threshold < 1.0, \\\n",
        "            'AssertionError: imputing_percentage_threshold is expected to be a float value between [0.0, 1.0], ' \\\n",
        "            f'got: {imputing_percentage_threshold}'\n",
        "\n",
        "        self._impute_missing_scores = impute_missing_scores\n",
        "        self._imputing_percentage_threshold = imputing_percentage_threshold\n",
        "\n",
        "    def _impute_missing_trend_scores(self, trend_scores: pd.Series) -> pd.Series:\n",
        "        missing_scores_percentage = trend_scores.isna().mean()\n",
        "\n",
        "        if missing_scores_percentage < self._imputing_percentage_threshold:\n",
        "            trend_scores[trend_scores == 0] = np.nan\n",
        "            trend_scores.interpolate(method='polynomial', order=5, inplace=True)\n",
        "            trend_scores[trend_scores == np.nan] = 0\n",
        "        else:\n",
        "            warnings.warn('Expected missing scores percentage to be less than '\n",
        "                          f'{self._imputing_percentage_threshold}, got {missing_scores_percentage}%. '\n",
        "                          f'Imputation process is skipped')\n",
        "        return trend_scores\n",
        "\n",
        "    def preprocess(self, trends_df: pd.DataFrame) -> pd.DataFrame:\n",
        "        trends_df.rename(columns={trends_df.columns[1]: 'trends'}, inplace=True)\n",
        "\n",
        "        if self._impute_missing_scores:\n",
        "            trends_df['trends'] = self._impute_missing_trend_scores(trend_scores=trends_df['trends'])\n",
        "        return trends_df\n"
      ],
      "metadata": {
        "id": "HViCeqW120sS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# database.preprocessing.coinapi.ohlcv - ohlcv.py"
      ],
      "metadata": {
        "id": "YMfcWr7A3HJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# from database.preprocessing.preprocessing import DatasetPreprocessing\n",
        "\n",
        "\n",
        "class OHLCVPreprocessing(DatasetPreprocessing):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    @staticmethod\n",
        "    def _preprocess_ohlcv_columns(ohlcv_df: pd.DataFrame):\n",
        "        ohlcv_df.drop(columns=['time_period_start', 'time_open', 'time_close'], inplace=True)\n",
        "        ohlcv_df.rename(columns={\n",
        "            'time_period_end': 'date',\n",
        "            'price_open': 'open',\n",
        "            'price_high': 'high',\n",
        "            'price_low': 'low',\n",
        "            'price_close': 'close',\n",
        "            'volume_traded': 'volume',\n",
        "            'trades_count': 'trades'\n",
        "        }, inplace=True)\n",
        "        ohlcv_df['date'] = ohlcv_df['date'].apply(lambda date: date.split('.')[0].replace('T', ' '))\n",
        "        ohlcv_df['hour'] = ohlcv_df['date'].apply(lambda date: int(date.split(' ')[1].split(':')[0]))\n",
        "        return ohlcv_df\n",
        "\n",
        "    @staticmethod\n",
        "    def _append_ohlcv_log_returns_to_df(ohlcv_df: pd.DataFrame) -> pd.DataFrame:\n",
        "        ohlcv_df['open_log_returns'] = np.log(ohlcv_df['open']).diff()\n",
        "        ohlcv_df['high_log_returns'] = np.log(ohlcv_df['high']).diff()\n",
        "        ohlcv_df['low_log_returns'] = np.log(ohlcv_df['low']).diff()\n",
        "        ohlcv_df['close_log_returns'] = np.log(ohlcv_df['close']).diff()\n",
        "        ohlcv_df['volume_log_returns'] = np.log(ohlcv_df['volume']).diff()\n",
        "        ohlcv_df['trades_log_returns'] = np.log(ohlcv_df['trades']).diff()\n",
        "        return ohlcv_df\n",
        "\n",
        "    def preprocess(self, ohlcv_df: pd.DataFrame) -> pd.DataFrame:\n",
        "        ohlcv_df = self._preprocess_ohlcv_columns(ohlcv_df=ohlcv_df)\n",
        "        ohlcv_df = self._append_ohlcv_log_returns_to_df(ohlcv_df=ohlcv_df)\n",
        "        return ohlcv_df\n"
      ],
      "metadata": {
        "id": "XWQ0gnQy20u_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# database.preprocessing.ta.ta - ta.py"
      ],
      "metadata": {
        "id": "T9rluSc73LJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# from database.preprocessing.preprocessing import DatasetPreprocessing\n",
        "\n",
        "\n",
        "class TechnicalAnalysisPreprocessing(DatasetPreprocessing):\n",
        "    def __init__(self, closes: pd.Series):\n",
        "        self._closes = closes\n",
        "\n",
        "    def preprocess(self, ta_df: pd.DataFrame) -> pd.DataFrame:\n",
        "        ta_df_columns = set(ta_df.columns)\n",
        "\n",
        "        if 'dema' in ta_df_columns:\n",
        "            ta_df['close_dema'] = self._closes - ta_df['dema']\n",
        "        if 'vwap' in ta_df_columns:\n",
        "            ta_df['close_vwap'] = self._closes - ta_df['vwap']\n",
        "        if 'bband_up' and 'bband_down' in ta_df_columns:\n",
        "            ta_df['bband_up_close'] = ta_df['bband_up'] - self._closes\n",
        "            ta_df['close_bband_down'] = self._closes - ta_df['bband_down']\n",
        "        if 'adl' in ta_df_columns:\n",
        "            ta_df['adl_diffs'] = ta_df['adl'].diff()\n",
        "        if 'obv' in ta_df_columns:\n",
        "            ta_df['obv_diffs'] = ta_df['obv'].diff()\n",
        "        return ta_df\n"
      ],
      "metadata": {
        "id": "DAzMWFFh20xn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# analysis.technical.indicators.indicator - indicator.py"
      ],
      "metadata": {
        "id": "jJ44WazP3NcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "\n",
        "class TechnicalIndicator(ABC):\n",
        "    def __init__(self, name: str or tuple[str, str]):\n",
        "        self._name = name\n",
        "\n",
        "    @property\n",
        "    def name(self) -> str or tuple[str, str]:\n",
        "        return self._name\n",
        "\n",
        "    def __hash__(self) -> int:\n",
        "        return hash(self.name)\n",
        "\n",
        "    def __call__(self, **kwargs) -> pd.Series or tuple[pd.Series, pd.Series]:\n",
        "        return self.compute_indicator_values(**kwargs)\n",
        "\n",
        "    def compute_indicator_values(self, **kwargs) -> pd.Series or tuple[pd.Series, pd.Series]:\n",
        "        indicator_values = self._compute_indicator_values(**kwargs)\n",
        "\n",
        "        assert (isinstance(self.name, str) and isinstance(indicator_values, pd.Series)) or \\\n",
        "               (isinstance(self.name, tuple) and isinstance(indicator_values, tuple)), \\\n",
        "            'AssertionError Indicator names does not match indicator values'\n",
        "\n",
        "        return indicator_values\n",
        "\n",
        "    @abstractmethod\n",
        "    def _compute_indicator_values(self, **kwargs) -> pd.Series or tuple[pd.Series, pd.Series]:\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "Vf5GyDiS200e"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# analysis.technical.indicators.adl - ADL.py"
      ],
      "metadata": {
        "id": "d1rxlm0l3Sh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from ta.volume import AccDistIndexIndicator\n",
        "# from analysis.technical.indicators.indicator import TechnicalIndicator\n",
        "\n",
        "\n",
        "class ADL(TechnicalIndicator):\n",
        "    def __init__(self):\n",
        "        super().__init__(name='adl')\n",
        "\n",
        "    def _compute_indicator_values(\n",
        "            self, highs: pd.Series,\n",
        "            lows: pd.Series,\n",
        "            closes: pd.Series,\n",
        "            volumes: pd.Series\n",
        "    ) -> pd.Series:\n",
        "        return AccDistIndexIndicator(\n",
        "            high=highs,\n",
        "            low=lows,\n",
        "            close=closes,\n",
        "            volume=volumes\n",
        "        ).acc_dist_index()\n"
      ],
      "metadata": {
        "id": "zwuAY-yv203R"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# analysis.technical.indicators.adx - ADX.py"
      ],
      "metadata": {
        "id": "GtY5XyaL3VFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from ta.trend import ADXIndicator\n",
        "# from analysis.technical.indicators.indicator import TechnicalIndicator\n",
        "\n",
        "\n",
        "class ADX(TechnicalIndicator):\n",
        "    def __init__(self):\n",
        "        super().__init__(name='adx')\n",
        "\n",
        "    def _compute_indicator_values(\n",
        "            self,\n",
        "            highs: pd.Series,\n",
        "            lows: pd.Series,\n",
        "            closes: pd.Series,\n",
        "            window: int = 14\n",
        "    ) -> pd.Series:\n",
        "        return ADXIndicator(high=highs, low=lows, close=closes, window=window).adx()\n"
      ],
      "metadata": {
        "id": "bIJu_0tO2056"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# analysis.technical.indicators.aroons - AROONS.py"
      ],
      "metadata": {
        "id": "jUGZE_za3aQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from ta.trend import AroonIndicator\n",
        "# from analysis.technical.indicators.indicator import TechnicalIndicator\n",
        "\n",
        "\n",
        "class AROONS(TechnicalIndicator):\n",
        "    def __init__(self):\n",
        "        super().__init__(name=('aroon_up', 'aroon_down'))\n",
        "\n",
        "    def _compute_indicator_values(self, closes: pd.Series, window: int = 25) -> tuple[pd.Series, pd.Series]:\n",
        "        aroon_values = AroonIndicator(close=closes, window=window)\n",
        "        return aroon_values.aroon_up(), aroon_values.aroon_down()\n"
      ],
      "metadata": {
        "id": "LBfEHkBh208c"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# analysis.technical.indicators.bbands - BBANDS.py"
      ],
      "metadata": {
        "id": "QH54DRN13evK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from ta.volatility import BollingerBands\n",
        "# from analysis.technical.indicators.indicator import TechnicalIndicator\n",
        "\n",
        "\n",
        "class BBANDS(TechnicalIndicator):\n",
        "    def __init__(self):\n",
        "        super().__init__(name=('bband_up', 'bband_down'))\n",
        "\n",
        "    def _compute_indicator_values(\n",
        "            self, closes: pd.Series,\n",
        "            window: int = 20,\n",
        "            window_deviation: int = 2\n",
        "    ) -> tuple[pd.Series, pd.Series]:\n",
        "        bbands_values = BollingerBands(close=closes, window=window, window_dev=window_deviation)\n",
        "        return bbands_values.bollinger_hband(), bbands_values.bollinger_lband()\n"
      ],
      "metadata": {
        "id": "ZUYNPoaU20_K"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# analysis.technical.indicators.cci - CCI.py"
      ],
      "metadata": {
        "id": "gCynYk-i3gr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from ta.trend import CCIIndicator\n",
        "# from analysis.technical.indicators.indicator import TechnicalIndicator\n",
        "\n",
        "\n",
        "class CCI(TechnicalIndicator):\n",
        "    def __init__(self):\n",
        "        super().__init__(name='cci')\n",
        "\n",
        "    def _compute_indicator_values(\n",
        "            self,\n",
        "            highs: pd.Series,\n",
        "            lows: pd.Series,\n",
        "            closes: pd.Series,\n",
        "            window: int = 20\n",
        "    ) -> pd.Series:\n",
        "        return CCIIndicator(\n",
        "            high=highs,\n",
        "            low=lows,\n",
        "            close=closes,\n",
        "            window=window\n",
        "        ).cci()\n"
      ],
      "metadata": {
        "id": "4lPGl1ga21Bz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# analysis.technical.indicators.dema - DEMA.py"
      ],
      "metadata": {
        "id": "OBaO1PUR3kv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from ta.trend import EMAIndicator\n",
        "# from analysis.technical.indicators.indicator import TechnicalIndicator\n",
        "\n",
        "\n",
        "class DEMA(TechnicalIndicator):\n",
        "    def __init__(self):\n",
        "        super().__init__(name='dema')\n",
        "\n",
        "    def _compute_indicator_values(self, closes: pd.Series, window: int = 15) -> pd.Series:\n",
        "        ema = EMAIndicator(close=closes, window=window).ema_indicator()\n",
        "        ema_of_ema = EMAIndicator(close=ema, window=window).ema_indicator()\n",
        "        return 2*ema - ema_of_ema\n"
      ],
      "metadata": {
        "id": "6NfmgVx621Em"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# analysis.technical.indicators.ema - EMA.py"
      ],
      "metadata": {
        "id": "8GZxdHaJ3mvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from ta.trend import EMAIndicator\n",
        "# from analysis.technical.indicators.indicator import TechnicalIndicator\n",
        "\n",
        "\n",
        "class EMA(TechnicalIndicator):\n",
        "    def __init__(self):\n",
        "        super().__init__(name='ema')\n",
        "\n",
        "    def _compute_indicator_values(self, closes: pd.Series, window: int = 14) -> pd.Series:\n",
        "        return EMAIndicator(close=closes, window=window).ema_indicator()\n"
      ],
      "metadata": {
        "id": "ewU2HrX421HX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# analysis.technical.indicators.macd - MACDSignalDiffs.py"
      ],
      "metadata": {
        "id": "z-_hNx6i3q6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from ta.trend import MACD\n",
        "# from analysis.technical.indicators.indicator import TechnicalIndicator\n",
        "\n",
        "\n",
        "class MACDSignalDiffs(TechnicalIndicator):\n",
        "    def __init__(self):\n",
        "        super().__init__(name='macd_signal_diffs')\n",
        "\n",
        "    def _compute_indicator_values(\n",
        "            self, closes: pd.Series,\n",
        "            short_window: int = 12,\n",
        "            long_window: int = 26,\n",
        "            signal_period=9\n",
        "    ) -> pd.Series:\n",
        "        return MACD(\n",
        "            close=closes,\n",
        "            window_slow=long_window,\n",
        "            window_fast=short_window,\n",
        "            window_sign=signal_period\n",
        "        ).macd_diff()\n"
      ],
      "metadata": {
        "id": "aNRTSm493rOW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# analysis.technical.indicators.obv - OBV.py\n"
      ],
      "metadata": {
        "id": "GTVE8mna3qPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from ta.volume import OnBalanceVolumeIndicator\n",
        "# from analysis.technical.indicators.indicator import TechnicalIndicator\n",
        "\n",
        "\n",
        "class OBV(TechnicalIndicator):\n",
        "    def __init__(self):\n",
        "        super().__init__(name='obv')\n",
        "\n",
        "    def _compute_indicator_values(self, closes: pd.Series, volumes: pd.Series) -> pd.Series:\n",
        "        return OnBalanceVolumeIndicator(\n",
        "            close=closes,\n",
        "            volume=volumes\n",
        "        ).on_balance_volume()\n"
      ],
      "metadata": {
        "id": "-Bo-_Sgj3qmq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# analysis.technical.indicators.rsi - RSI.py"
      ],
      "metadata": {
        "id": "r3w8-Qg8304Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from ta.momentum import RSIIndicator\n",
        "# from analysis.technical.indicators.indicator import TechnicalIndicator\n",
        "\n",
        "\n",
        "class RSI(TechnicalIndicator):\n",
        "    def __init__(self):\n",
        "        super().__init__(name='rsi')\n",
        "\n",
        "    def _compute_indicator_values(self, closes: pd.Series, window: int = 14) -> pd.Series:\n",
        "        return RSIIndicator(close=closes, window=window).rsi()\n"
      ],
      "metadata": {
        "id": "9bqcjHI330qA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# analysis.technical.indicators.stoch - STOCH.py"
      ],
      "metadata": {
        "id": "QxNcaZiR30bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from ta.momentum import StochasticOscillator\n",
        "# from analysis.technical.indicators.indicator import TechnicalIndicator\n",
        "\n",
        "\n",
        "class STOCH(TechnicalIndicator):\n",
        "    def __init__(self):\n",
        "        super().__init__(name='stoch')\n",
        "\n",
        "    def _compute_indicator_values(\n",
        "            self,\n",
        "            highs: pd.Series,\n",
        "            lows: pd.Series,\n",
        "            closes: pd.Series,\n",
        "            window: int = 14\n",
        "    ) -> pd.Series:\n",
        "        return StochasticOscillator(high=highs, low=lows, close=closes, window=window).stoch()\n"
      ],
      "metadata": {
        "id": "kH-G_1kb32Zx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# analysis.technical.indicators.vwap - VWAP.py"
      ],
      "metadata": {
        "id": "572MuxG73-nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from ta.volume import VolumeWeightedAveragePrice\n",
        "# from analysis.technical.indicators.indicator import TechnicalIndicator\n",
        "\n",
        "\n",
        "class VWAP(TechnicalIndicator):\n",
        "    def __init__(self):\n",
        "        super().__init__(name='vwap')\n",
        "\n",
        "    def _compute_indicator_values(\n",
        "            self,\n",
        "            highs: pd.Series,\n",
        "            lows: pd.Series,\n",
        "            closes: pd.Series,\n",
        "            volumes: pd.Series,\n",
        "            window: int = 10\n",
        "    ) -> pd.Series:\n",
        "        return VolumeWeightedAveragePrice(\n",
        "            high=highs,\n",
        "            low=lows,\n",
        "            close=closes,\n",
        "            volume=volumes,\n",
        "            window=window\n",
        "        ).volume_weighted_average_price()\n"
      ],
      "metadata": {
        "id": "MVtyNKvf3_Cr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# analysis.technical.technical - technical.py"
      ],
      "metadata": {
        "id": "8i8B6HfJ3_UA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# from analysis.technical.indicators.indicator import TechnicalIndicator\n",
        "\n",
        "\n",
        "class TechnicalAnalysis:\n",
        "    def __init__(self, dates: pd.Series):\n",
        "        self._dates = dates\n",
        "\n",
        "    def compute_technical_indicators(self, ta_config_dict: dict[TechnicalIndicator, dict]) -> pd.DataFrame:\n",
        "        ta = {'date': self._dates}\n",
        "\n",
        "        for indicator, params in ta_config_dict.items():\n",
        "            indicator_name = indicator.name\n",
        "            indicator_values = indicator.compute_indicator_values(**params)\n",
        "\n",
        "            if isinstance(indicator_name, str):\n",
        "                ta[indicator_name] = indicator_values\n",
        "            else:\n",
        "                for name, values in zip(indicator_name, indicator_values):\n",
        "                    ta[name] = values\n",
        "        return pd.DataFrame(data=ta)\n"
      ],
      "metadata": {
        "id": "4diD8MMk3_2m"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# analysis.technical.configs.config - config.py"
      ],
      "metadata": {
        "id": "ZU-VTddu4HCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from abc import ABC, abstractmethod\n",
        "# from analysis.technical.indicators.indicator import TechnicalIndicator\n",
        "\n",
        "\n",
        "class TAConfig(ABC):\n",
        "    @abstractmethod\n",
        "    def get_technical_analysis_config_dict(\n",
        "            self,\n",
        "            opens: pd.Series,\n",
        "            highs: pd.Series,\n",
        "            lows: pd.Series,\n",
        "            closes: pd.Series,\n",
        "            volumes: pd.Series\n",
        "    ) -> dict[TechnicalIndicator, dict]:\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "FOchqEJL4Hbq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# analysis.technical.configs.standard - standard.py"
      ],
      "metadata": {
        "id": "8VXmzva84HtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# from analysis.technical.configs.config import TAConfig\n",
        "# from analysis.technical.indicators.indicator import TechnicalIndicator\n",
        "# from analysis.technical.indicators.dema import DEMA\n",
        "# from analysis.technical.indicators.vwap import VWAP\n",
        "# from analysis.technical.indicators.macd import MACDSignalDiffs\n",
        "# from analysis.technical.indicators.rsi import RSI\n",
        "# from analysis.technical.indicators.stoch import STOCH\n",
        "# from analysis.technical.indicators.cci import CCI\n",
        "# from analysis.technical.indicators.adx import ADX\n",
        "# from analysis.technical.indicators.aroons import AROONS\n",
        "# from analysis.technical.indicators.bbands import BBANDS\n",
        "# from analysis.technical.indicators.adl import ADL\n",
        "# from analysis.technical.indicators.obv import OBV\n",
        "\n",
        "\n",
        "class StandardTAConfig(TAConfig):\n",
        "    def __init__(\n",
        "            self,\n",
        "            dema_window: int = 15,\n",
        "            vwap_window: int = 10,\n",
        "            macd_short_window: int = 12,\n",
        "            macd_long_window: int = 26,\n",
        "            macd_signal_period: int = 9,\n",
        "            rsi_window: int = 14,\n",
        "            stoch_window: int = 14,\n",
        "            cci_window: int = 20,\n",
        "            adx_window: int = 14,\n",
        "            aroons_window: int = 25,\n",
        "            bbands_window: int = 20\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self._dema_window = dema_window\n",
        "        self._vwap_window = vwap_window\n",
        "        self._macd_short_window = macd_short_window\n",
        "        self._macd_long_window = macd_long_window\n",
        "        self._macd_signal_period = macd_signal_period\n",
        "        self._rsi_window = rsi_window\n",
        "        self._stoch_window = stoch_window\n",
        "        self._cci_window = cci_window\n",
        "        self._adx_window = adx_window\n",
        "        self._aroons_window = aroons_window\n",
        "        self._bbands_window = bbands_window\n",
        "\n",
        "    def get_technical_analysis_config_dict(\n",
        "            self,\n",
        "            opens: pd.Series,\n",
        "            highs: pd.Series,\n",
        "            lows: pd.Series,\n",
        "            closes: pd.Series,\n",
        "            volumes: pd.Series\n",
        "    ) -> dict[TechnicalIndicator, dict]:\n",
        "        return {\n",
        "            DEMA(): {'closes': closes, 'window': self._dema_window},\n",
        "            VWAP(): {\n",
        "                'highs': highs,\n",
        "                'lows': lows,\n",
        "                'closes': closes,\n",
        "                'volumes': volumes,\n",
        "                'window': self._vwap_window\n",
        "            },\n",
        "            MACDSignalDiffs(): {\n",
        "                'closes': closes,\n",
        "                'short_window': self._macd_short_window,\n",
        "                'long_window': self._macd_long_window,\n",
        "                'signal_period': self._macd_signal_period\n",
        "            },\n",
        "            RSI(): {'closes': closes, 'window': self._rsi_window},\n",
        "            STOCH(): {'highs': highs, 'lows': lows, 'closes': closes, 'window': self._stoch_window},\n",
        "            CCI(): {'highs': highs, 'lows': lows, 'closes': closes, 'window': self._cci_window},\n",
        "            ADX(): {'highs': highs, 'lows': lows, 'closes': closes, 'window': self._adx_window},\n",
        "            AROONS(): {'closes': closes, 'window': self._aroons_window},\n",
        "            BBANDS(): {'closes': closes, 'window': self._bbands_window},\n",
        "            ADL(): {'highs': highs, 'lows': lows, 'closes': closes, 'volumes': volumes},\n",
        "            OBV(): {'closes': closes, 'volumes': volumes}\n",
        "        }\n"
      ],
      "metadata": {
        "id": "JZGLPO3P4IEW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# database.network.network - network.py"
      ],
      "metadata": {
        "id": "kZ73d3ea4IU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# from database.entities.crypto import Crypto\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "\n",
        "class DatasetDownloader(ABC):\n",
        "    def __init__(self, date_column_name: str, verbose: bool):\n",
        "        self._date_column_name = date_column_name\n",
        "        self._verbose = verbose\n",
        "\n",
        "    @property\n",
        "    def date_column_name(self) -> str:\n",
        "        return self._date_column_name\n",
        "\n",
        "    @property\n",
        "    def verbose(self) -> bool:\n",
        "        return self._verbose\n",
        "\n",
        "    def _store_dataset(self, dataset_df: pd.DataFrame, filepath: str, columns: list or None = None):\n",
        "        assert not dataset_df.duplicated(subset=self.date_column_name).any(), \\\n",
        "            f'AssertionError: Date column is expected to be unique, got duplicates'\n",
        "\n",
        "        assert dataset_df[self.date_column_name].is_monotonic_increasing, \\\n",
        "            f'AssertionError: Date column is expected to be monotonic and increasing'\n",
        "\n",
        "        dataset_df.to_csv(filepath, columns=columns, index=False)\n",
        "\n",
        "    @abstractmethod\n",
        "    def download_historical_data(self, crypto: Crypto, history_filepath: str) -> bool:\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def update_historical_data(self, crypto: Crypto, history_filepath: str) -> bool:\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "ZSFe4BUx4Itq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# database.network.coinapi.coinapi - coinapi.py"
      ],
      "metadata": {
        "id": "hjYdYI6s4TUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from abc import ABC, abstractmethod\n",
        "from urllib.parse import urlencode\n",
        "# from database.network.network import DatasetDownloader\n",
        "\n",
        "\n",
        "class CoinAPIDownloader(DatasetDownloader, ABC):\n",
        "    def __init__(self, verbose: bool):\n",
        "        super().__init__(date_column_name=self._get_date_column_name(), verbose=verbose)\n",
        "\n",
        "        self._api_key_list = [\n",
        "            '70E10174-E29D-449F-9F2E-6E8362931DD9',\n",
        "            '27E5E40C-7A6B-45EB-A5C8-8311B049A741',\n",
        "            '8F6252DE-0AD7-478F-91C7-141141E8BE8B',\n",
        "            '3B49210E-100B-4F8D-9011-2BA5D38274BA',\n",
        "            'BF6BF46F-B44B-416E-9656-2D2AAFBC058B',\n",
        "            'B21A98A2-C953-4C73-84CF-CFFB6F712200',\n",
        "            '51667E99-7686-4496-B23D-6DA54F7E37AE',\n",
        "            '0921F87B-BF55-4B78-B8B0-E023B4D7A2E2',\n",
        "            '3F9E3251-029C-457A-9ADA-7F21A440AAF9',\n",
        "            '41EBEA2D-1A4B-4654-8A41-186639B9AB9F',\n",
        "            '6B93AEC2-910C-4064-80FB-91AED487AB97',\n",
        "            '83049379-23DE-4CB0-8299-7137BB836D48',\n",
        "            'B08FCA1F-F454-4C34-AC01-42F16354BCBC',\n",
        "            '12E5D72C-25A6-4ED6-8384-7C291EC43768',\n",
        "            '4F287859-5A00-47EF-AC91-8A2629F8C6A1',\n",
        "            '3744F705-2C4A-406C-AA96-EB1B557A84EF',\n",
        "            '3F77D500-457E-4A96-9CE1-1DEF3FC7033B',\n",
        "            '455C2228-0D6F-4B62-8336-4BAA24C1A46E',\n",
        "            '7E37E058-670C-4ED6-B7BE-DC00F309D9FF',\n",
        "            '0F517C3D-162C-4C5E-AE18-544B201C9BC0'\n",
        "        ]\n",
        "\n",
        "    @property\n",
        "    def api_key_list(self) -> list[str]:\n",
        "        return self._api_key_list\n",
        "\n",
        "    @abstractmethod\n",
        "    def _get_date_column_name(self) -> str:\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def _get_request_params(self) -> dict[str, str]:\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def _encode_request_url(base_url: str, request_params: dict, api_key: str) -> str:\n",
        "        request_params['apikey'] = api_key\n",
        "        encoded_params = urlencode(request_params)\n",
        "        return f'{base_url}?{encoded_params}'\n",
        "\n",
        "    def _get_response(self, base_url: str, request_params: dict) -> requests.Response or None:\n",
        "        for api_key in self._api_key_list:\n",
        "            if self._verbose:\n",
        "                print(f'Using apikey: {api_key}')\n",
        "\n",
        "            encoded_request_url = self._encode_request_url(\n",
        "                base_url=base_url,\n",
        "                request_params=request_params,\n",
        "                api_key=api_key\n",
        "            )\n",
        "            response = requests.get(encoded_request_url)\n",
        "\n",
        "            if self._verbose:\n",
        "                print(f'Response Status: {response.status_code} - {response.reason}')\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                return response\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "mtf-eqLV4Tn5"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# database.network.coinapi.ohlcv - ohlcv.py"
      ],
      "metadata": {
        "id": "3fGmYW4S4T9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "from enum import Enum\n",
        "# from database.entities.crypto import Crypto\n",
        "# from database.network.coinapi.coinapi import CoinAPIDownloader\n",
        "\n",
        "\n",
        "class OHLCVDownloader(CoinAPIDownloader):\n",
        "    class HistoricalFrequency(Enum):\n",
        "        MINUTE = '1MIN'\n",
        "        HOUR = '1HRS'\n",
        "\n",
        "    def __init__(self, historical_frequency: HistoricalFrequency or str, verbose: bool):\n",
        "        if isinstance(historical_frequency, str):\n",
        "            if historical_frequency == '1HRS':\n",
        "                self._historical_frequency = self.HistoricalFrequency.HOUR\n",
        "            elif historical_frequency == '1MIN':\n",
        "                self._historical_frequency = self.HistoricalFrequency.MINUTE\n",
        "            else:\n",
        "                raise NotImplementedError(f'\"{historical_frequency}\" frequency has not been implemented yet')\n",
        "        else:\n",
        "            self._historical_frequency = historical_frequency\n",
        "\n",
        "        super().__init__(verbose=verbose)\n",
        "\n",
        "        self._history_request_url = 'https://rest.coinapi.io/v1/ohlcv/{}/USD/history'\n",
        "        self._latest_request_url = 'https://rest.coinapi.io/v1/ohlcv/{}/USD/latest'\n",
        "        self._download_limit = 100000\n",
        "        self._update_limit = 1000\n",
        "\n",
        "    def _get_date_column_name(self) -> str:\n",
        "        return 'time_period_end'\n",
        "\n",
        "    def _get_request_params(self) -> dict:\n",
        "        return {\n",
        "            'period_id': self._historical_frequency.value,\n",
        "            'output_format': 'csv',\n",
        "            'csv_set_delimiter': ',',\n",
        "            'time_start': '{}-{}-{}T00:00:00',\n",
        "            'limit': '{}'\n",
        "        }\n",
        "\n",
        "    def download_historical_data(self, crypto: Crypto, history_filepath: str) -> bool:\n",
        "        if self.verbose:\n",
        "            print(f'Downloading {crypto.name} market history data for {crypto.start_year}')\n",
        "\n",
        "        request_params = self._get_request_params()\n",
        "        request_params['time_start'] = request_params['time_start'].format(crypto.start_year, '01', '01')\n",
        "        request_params['limit'] = request_params['limit'].format(self._download_limit)\n",
        "        base_url = self._history_request_url.format(crypto.symbol)\n",
        "\n",
        "        response = self._get_response(\n",
        "            base_url=base_url,\n",
        "            request_params=request_params\n",
        "        )\n",
        "        if response is not None and response.status_code == 200:\n",
        "            ohlcv_df = pd.read_csv(io.StringIO(response.text), sep=',')\n",
        "            super()._store_dataset(dataset_df=ohlcv_df, filepath=history_filepath)\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def update_historical_data(self, crypto: Crypto, history_filepath: str) -> bool:\n",
        "        if self.verbose:\n",
        "            print(f'Updating {crypto.name} market latest data for {crypto.start_year}')\n",
        "\n",
        "        request_params = self._get_request_params()\n",
        "        request_params['limit'] = request_params['limit'].format(self._update_limit)\n",
        "        del request_params['time_start']\n",
        "        base_url = self._latest_request_url.format(crypto.symbol)\n",
        "\n",
        "        response = self._get_response(\n",
        "            base_url=base_url,\n",
        "            request_params=request_params\n",
        "        )\n",
        "\n",
        "        if response is not None and response.status_code == 200:\n",
        "            history_df = pd.read_csv(history_filepath)\n",
        "            latest_df = pd.read_csv(io.StringIO(response.text), sep=',').sort_values(\n",
        "                by=self.date_column_name, ascending=True\n",
        "            )\n",
        "            merged_df = pd.concat((history_df, latest_df), ignore_index=True)\n",
        "            merged_df.drop_duplicates(subset=self.date_column_name, inplace=True)\n",
        "\n",
        "            super()._store_dataset(dataset_df=merged_df, filepath=history_filepath)\n",
        "            return True\n",
        "        return False\n"
      ],
      "metadata": {
        "id": "XVJO0FlM4UUu"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# database.datasets.builder - builder.py"
      ],
      "metadata": {
        "id": "9wtBohbC4Ump"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from functools import reduce\n",
        "# from analysis.technical.configs.config import TAConfig\n",
        "# from analysis.technical.configs.standard import StandardTAConfig\n",
        "# from analysis.technical.technical import TechnicalAnalysis\n",
        "# from database.preprocessing.gtrends.gtrends import GoogleTrendsPreprocessing\n",
        "# from database.preprocessing.coinapi.ohlcv import OHLCVPreprocessing\n",
        "# from database.preprocessing.ta.ta import TechnicalAnalysisPreprocessing\n",
        "\n",
        "\n",
        "class DatasetBuilder:\n",
        "    def __init__(self):\n",
        "        self._key_column = 'date'\n",
        "\n",
        "    @staticmethod\n",
        "    def _import_ohlcv_dataset(ohlcv_history_filepath: str) -> pd.DataFrame:\n",
        "        ohlcv_df = pd.read_csv(ohlcv_history_filepath)\n",
        "        ohlcv_df = OHLCVPreprocessing().preprocess(ohlcv_df=ohlcv_df)\n",
        "        return ohlcv_df\n",
        "\n",
        "    @staticmethod\n",
        "    def _compute_technical_indicators(\n",
        "            ohlcv_df: pd.DataFrame,\n",
        "            ta_config: TAConfig,\n",
        "    ) -> pd.DataFrame:\n",
        "        ta_config_dict = ta_config.get_technical_analysis_config_dict(\n",
        "            opens=ohlcv_df['open'],\n",
        "            highs=ohlcv_df['high'],\n",
        "            lows=ohlcv_df['low'],\n",
        "            closes=ohlcv_df['close'],\n",
        "            volumes=ohlcv_df['volume']\n",
        "        )\n",
        "        ta_df = TechnicalAnalysis(dates=ohlcv_df['date']).compute_technical_indicators(ta_config_dict=ta_config_dict)\n",
        "        ta_df = TechnicalAnalysisPreprocessing(closes=ohlcv_df['close']).preprocess(ta_df=ta_df)\n",
        "        return ta_df\n",
        "\n",
        "    @staticmethod\n",
        "    def _import_gtrends_dataset(\n",
        "            gtrends_history_filepath: str,\n",
        "            impute_missing_gtrends: bool,\n",
        "            gtrends_imputing_percentage_threshold: float\n",
        "    ):\n",
        "        trends_df = pd.read_csv(gtrends_history_filepath)\n",
        "        return GoogleTrendsPreprocessing(\n",
        "            impute_missing_scores=impute_missing_gtrends,\n",
        "            imputing_percentage_threshold=gtrends_imputing_percentage_threshold\n",
        "        ).preprocess(trends_df=trends_df)\n",
        "\n",
        "    def _merge_datasets(self, dataset_df_list: list) -> pd.DataFrame:\n",
        "        for df in dataset_df_list:\n",
        "            assert self._key_column in df.columns, \\\n",
        "                f'AssertionError: Key column: \"{self._key_column}\" is missing from a dataset. Cannot merge datasets'\n",
        "\n",
        "        return dataset_df_list[0] if len(dataset_df_list) == 1 else \\\n",
        "            reduce(lambda left, right: pd.merge(left, right, on=self._key_column, how='left'), dataset_df_list)\n",
        "\n",
        "    @staticmethod\n",
        "    def _handle_missing_values(dataset_df: pd.DataFrame) -> pd.DataFrame:\n",
        "        dataset_df['hour'] = dataset_df['date'].apply(lambda date: int(date.split(' ')[1].split(':')[0]))\n",
        "\n",
        "        if 'trends' in dataset_df.columns:\n",
        "            dataset_df['trends'].replace({np.nan: 0.0}, inplace=True)\n",
        "\n",
        "        dataset_df.dropna(inplace=True)\n",
        "\n",
        "        assert not dataset_df.isna().any().any(), \\\n",
        "            f'AssertionError: Imputation failed or incomplete. ' \\\n",
        "            f'Found missing values at columns: {dataset_df.columns[dataset_df.isna().any()]}'\n",
        "\n",
        "        return dataset_df\n",
        "\n",
        "    def build_dataset(\n",
        "            self,\n",
        "            ohlcv_history_filepath: str,\n",
        "            gtrends_history_filepath: str or None,\n",
        "            dataset_save_filepath: str,\n",
        "            ta_config: TAConfig = StandardTAConfig,\n",
        "            impute_missing_gtrends: bool = True,\n",
        "            gtrends_imputing_percentage_threshold: float = 0.1\n",
        "    ):\n",
        "        ohlcv_df = self._import_ohlcv_dataset(ohlcv_history_filepath=ohlcv_history_filepath)\n",
        "        ta_df = self._compute_technical_indicators(ohlcv_df=ohlcv_df, ta_config=ta_config)\n",
        "        gtrends_df = self._import_gtrends_dataset(\n",
        "            gtrends_history_filepath=gtrends_history_filepath,\n",
        "            impute_missing_gtrends=impute_missing_gtrends,\n",
        "            gtrends_imputing_percentage_threshold=gtrends_imputing_percentage_threshold\n",
        "        )\n",
        "\n",
        "        num_expected_samples = ohlcv_df.shape[0]\n",
        "        merged_dataset_df = self._merge_datasets(dataset_df_list=[ohlcv_df, ta_df, gtrends_df])\n",
        "\n",
        "        assert num_expected_samples == merged_dataset_df.shape[0], \\\n",
        "            'AssertionError: Merged dataset size mismatch: ' \\\n",
        "            f'Expected {num_expected_samples} samples, got {merged_dataset_df.shape[0]}'\n",
        "\n",
        "        dataset_df = self._handle_missing_values(dataset_df=merged_dataset_df)\n",
        "        dataset_df.to_csv(dataset_save_filepath, index=False)\n"
      ],
      "metadata": {
        "id": "tbPjfyJg4VJX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# database.network.gtrends.gtrends - gtrends.py"
      ],
      "metadata": {
        "id": "MVL-pCke4dmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import date\n",
        "from pytrends.request import TrendReq\n",
        "# from database.entities.crypto import Crypto\n",
        "# from database.network.network import DatasetDownloader\n",
        "\n",
        "\n",
        "class GoogleTrendsDownloader(DatasetDownloader):\n",
        "    def __init__(self, verbose: bool = True):\n",
        "        super().__init__(date_column_name='date', verbose=verbose)\n",
        "\n",
        "    def _download_year_trends(self, keyword: str, year: int) -> pd.DataFrame:\n",
        "        today = date.today()\n",
        "\n",
        "        if year == today.year:\n",
        "            month_end = today.month\n",
        "            day_end = today.day\n",
        "        else:\n",
        "            month_end = 12\n",
        "            day_end = 31\n",
        "\n",
        "        return TrendReq().get_historical_interest(\n",
        "            keywords=[keyword],\n",
        "            year_start=year,\n",
        "            month_start=1,\n",
        "            day_start=1,\n",
        "            hour_start=0,\n",
        "            year_end=year,\n",
        "            month_end=month_end,\n",
        "            day_end=day_end,\n",
        "            hour_end=23\n",
        "        ).reset_index().drop_duplicates(subset=self.date_column_name)\n",
        "\n",
        "    def download_historical_data(self, crypto: Crypto, history_filepath: str) -> bool:\n",
        "        if self.verbose:\n",
        "            print(f'Downloading {crypto.name} trends. It might take some time...')\n",
        "\n",
        "        trends_df_list = []\n",
        "        today_year = date.today().year\n",
        "        for year in range(crypto.start_year, today_year + 1):\n",
        "            trends_df_list.append(self._download_year_trends(keyword=crypto.name, year=year))\n",
        "\n",
        "        trends_df = pd.concat(trends_df_list, ignore_index=True)\n",
        "\n",
        "        super()._store_dataset(\n",
        "            dataset_df=trends_df,\n",
        "            filepath=history_filepath,\n",
        "            columns=[self.date_column_name, crypto.name]\n",
        "        )\n",
        "        return True\n",
        "\n",
        "    def update_historical_data(self, crypto: Crypto, history_filepath: str) -> bool:\n",
        "        if self.verbose:\n",
        "            print(f'Updating {crypto.name} trends history')\n",
        "\n",
        "        current_year = date.today().year\n",
        "        history_df = pd.read_csv(history_filepath)\n",
        "        history_df = history_df[history_df[self.date_column_name] < str(current_year)]\n",
        "        latest_df = self._download_year_trends(keyword=crypto.name, year=current_year)\n",
        "        merged_df = pd.concat((history_df, latest_df), ignore_index=True)\n",
        "        merged_df.drop_duplicates(subset=self.date_column_name, inplace=True)\n",
        "\n",
        "        assert not merged_df.duplicated(subset=self.date_column_name).any(), \\\n",
        "            'AssertionError: Duplicates found on Google Trends dates'\n",
        "\n",
        "        super()._store_dataset(\n",
        "            dataset_df=merged_df,\n",
        "            filepath=history_filepath,\n",
        "            columns=[self.date_column_name, crypto.name]\n",
        "        )\n",
        "        return True\n"
      ],
      "metadata": {
        "id": "NcX0W7cE4d8A"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# database.network.downloader - downloader.py"
      ],
      "metadata": {
        "id": "iwf1qjhP4eKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from database.entities.crypto import Crypto\n",
        "# from database.network.coinapi.ohlcv import OHLCVDownloader\n",
        "# from database.network.gtrends.gtrends import GoogleTrendsDownloader\n",
        "\n",
        "\n",
        "class CryptoDatasetDownloader:\n",
        "    def download_crypto_datasets(\n",
        "            self,\n",
        "            crypto: Crypto,\n",
        "            ohlcv_history_filepath: str,\n",
        "            gtrends_history_filepath: str,\n",
        "            historical_frequency: OHLCVDownloader.HistoricalFrequency or str,\n",
        "            verbose: bool = True\n",
        "    ) -> bool:\n",
        "        ohlcv_downloader = OHLCVDownloader(historical_frequency=historical_frequency, verbose=verbose)\n",
        "        gtrends_downloader = GoogleTrendsDownloader(verbose=verbose)\n",
        "\n",
        "        if ohlcv_downloader.download_historical_data(\n",
        "                crypto=crypto,\n",
        "                history_filepath=ohlcv_history_filepath.format(crypto.symbol)\n",
        "        ) and gtrends_downloader.download_historical_data(\n",
        "            crypto=crypto,\n",
        "            history_filepath=gtrends_history_filepath.format(crypto.symbol)\n",
        "        ):\n",
        "            if verbose:\n",
        "                print(f'Successfully downloaded {crypto.symbol} dataset')\n",
        "\n",
        "            return True\n",
        "\n",
        "        if verbose:\n",
        "            print('Download failed')\n",
        "\n",
        "        return False\n"
      ],
      "metadata": {
        "id": "mM7F-KO64ekb"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# config - import config.py"
      ],
      "metadata": {
        "id": "1u1yXUaZ4e8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from database.entities.crypto import Crypto\n",
        "# from database.network.coinapi.ohlcv import OHLCVDownloader\n",
        "\n",
        "# --- Database ---\n",
        "supported_cryptos = {\n",
        "    'BTC': Crypto(symbol='BTC', name='bitcoin', start_year=2017),\n",
        "    'ETH': Crypto(symbol='ETH', name='ethereum', start_year=2017),\n",
        "    'SOL': Crypto(symbol='SOL',  name='solana', start_year=2020),\n",
        "    'ADA': Crypto(symbol='ADA', name='ada', start_year=2017),\n",
        "    'BNB': Crypto(symbol='BNB', name='bnb', start_year=2019),\n",
        "    'XRP': Crypto(symbol='XRP', name='xrp', start_year=2019),\n",
        "    'DOGE': Crypto(symbol='DOGE', name='doge', start_year=2020),\n",
        "    'MATIC': Crypto(symbol='MATIC', name='polygon', start_year=2020),\n",
        "    'TRON': Crypto(symbol='TRON', name='tron', start_year=2018),\n",
        "    'LTC': Crypto(symbol='LTC', name='litecoin', start_year=2018),\n",
        "    'DOT': Crypto(symbol='DOT', name='polkadot', start_year=2021),\n",
        "    'AVAX': Crypto(symbol='AVAX', name='avalanche', start_year=2021),\n",
        "    'XMR': Crypto(symbol='XMR', name='monero', start_year=2018),\n",
        "    'BAT': Crypto(symbol='BAT', name='basic authentication token', start_year=2018),\n",
        "    'LRC': Crypto(symbol='LRC', name='loopring', start_year=2018)\n",
        "}\n",
        "\n",
        "ohlcv_dataset_period_id = OHLCVDownloader.HistoricalFrequency.HOUR\n",
        "ohlcv_history_filepath = 'database/storage/downloads/ohlcv/{}.csv'\n",
        "gtrends_history_filepath = 'database/storage/downloads/gtrends/{}.csv'\n",
        "dataset_save_filepath = 'database/storage/datasets/{}.csv'\n",
        "all_features = [\n",
        "    'date', 'open', 'high', 'low', 'close', 'volume', 'trades',\n",
        "    'open_log_returns', 'high_log_returns', 'low_log_returns',\n",
        "    'close_log_returns', 'volume_log_returns', 'trades_log_returns', 'hour',\n",
        "    'dema', 'vwap', 'bband_up', 'bband_down', 'adl', 'obv',\n",
        "    'macd_signal_diffs', 'stoch', 'aroon_up', 'aroon_down', 'rsi', 'adx', 'cci',\n",
        "    'close_dema', 'close_vwap', 'bband_up_close', 'close_bband_down', 'adl_diffs2', 'obv_diffs2', 'trends'\n",
        "]\n",
        "regression_features = [\n",
        "    'open_log_returns', 'high_log_returns', 'low_log_returns',\n",
        "    'close_log_returns', 'volume_log_returns', 'trades_log_returns', 'hour',\n",
        "    'macd_signal_diffs', 'stoch', 'aroon_up', 'aroon_down', 'rsi', 'adx', 'cci',\n",
        "    'close_dema', 'close_vwap', 'bband_up_close', 'close_bband_down', 'adl_diffs2', 'obv_diffs2', 'trends'\n",
        "]\n",
        "\n",
        "# --- Model ---\n",
        "checkpoint_dir = 'database/storage/checkpoints/'\n",
        "\n",
        "# --- Clustering ---\n",
        "crypto_clusters = [\n",
        "    ['BTC', 'ETH', 'SOL', 'ADA', 'XPR', 'DOGE', 'DOT', 'AVAX', 'BAT', 'LRC'],\n",
        "    ['ETH', 'BNB', 'MATIC', 'TRON', 'LTC', 'XMR']\n",
        "]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "__wTMeFx4fQQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# download_datasets.py"
      ],
      "metadata": {
        "id": "4lWutezf4ofk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "# import config\n",
        "# from analysis.technical.configs.standard import StandardTAConfig\n",
        "# from database.datasets.builder import DatasetBuilder\n",
        "# from database.network.downloader import CryptoDatasetDownloader\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "ta_config = StandardTAConfig()\n",
        "import_gtrends = True\n",
        "impute_missing_gtrends = True\n",
        "gtrends_imputing_percentage_threshold = 0.1\n",
        "verbose = True\n",
        "\n",
        "\n",
        "def main():\n",
        "    downloader = CryptoDatasetDownloader()\n",
        "    builder = DatasetBuilder()\n",
        "\n",
        "    for crypto_symbol, crypto in supported_cryptos.items():\n",
        "        if downloader.download_crypto_datasets(\n",
        "            crypto=crypto,\n",
        "            ohlcv_history_filepath=ohlcv_history_filepath,\n",
        "            gtrends_history_filepath=gtrends_history_filepath,\n",
        "            historical_frequency=ohlcv_dataset_period_id,\n",
        "            verbose=verbose\n",
        "        ):\n",
        "            builder.build_dataset(\n",
        "                ohlcv_history_filepath=ohlcv_history_filepath.format(crypto_symbol),\n",
        "                gtrends_history_filepath=gtrends_history_filepath.format(crypto_symbol),\n",
        "                dataset_save_filepath=dataset_save_filepath.format(crypto_symbol),\n",
        "                ta_config=ta_config,\n",
        "                impute_missing_gtrends=impute_missing_gtrends,\n",
        "                gtrends_imputing_percentage_threshold=gtrends_imputing_percentage_threshold\n",
        "            )\n",
        "\n",
        "            if verbose:\n",
        "                print(f'Successfully has built {crypto_symbol} dataset')\n",
        "        else:\n",
        "            if verbose:\n",
        "                print(f'Download of {crypto_symbol} has been aborted')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "ac7FYx4e4o9v",
        "outputId": "e01d0194-1729-4027-a0ef-8306eb6794cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading bitcoin market history data for 2017\n",
            "Using apikey: 70E10174-E29D-449F-9F2E-6E8362931DD9\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 27E5E40C-7A6B-45EB-A5C8-8311B049A741\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 8F6252DE-0AD7-478F-91C7-141141E8BE8B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 3B49210E-100B-4F8D-9011-2BA5D38274BA\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: BF6BF46F-B44B-416E-9656-2D2AAFBC058B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: B21A98A2-C953-4C73-84CF-CFFB6F712200\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 51667E99-7686-4496-B23D-6DA54F7E37AE\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 0921F87B-BF55-4B78-B8B0-E023B4D7A2E2\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F9E3251-029C-457A-9ADA-7F21A440AAF9\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 41EBEA2D-1A4B-4654-8A41-186639B9AB9F\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 6B93AEC2-910C-4064-80FB-91AED487AB97\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 83049379-23DE-4CB0-8299-7137BB836D48\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: B08FCA1F-F454-4C34-AC01-42F16354BCBC\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 12E5D72C-25A6-4ED6-8384-7C291EC43768\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 4F287859-5A00-47EF-AC91-8A2629F8C6A1\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3744F705-2C4A-406C-AA96-EB1B557A84EF\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F77D500-457E-4A96-9CE1-1DEF3FC7033B\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 455C2228-0D6F-4B62-8336-4BAA24C1A46E\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 7E37E058-670C-4ED6-B7BE-DC00F309D9FF\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 0F517C3D-162C-4C5E-AE18-544B201C9BC0\n",
            "Response Status: 404 - Not Found\n",
            "Download failed\n",
            "Download of BTC has been aborted\n",
            "Downloading ethereum market history data for 2017\n",
            "Using apikey: 70E10174-E29D-449F-9F2E-6E8362931DD9\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 27E5E40C-7A6B-45EB-A5C8-8311B049A741\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 8F6252DE-0AD7-478F-91C7-141141E8BE8B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 3B49210E-100B-4F8D-9011-2BA5D38274BA\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: BF6BF46F-B44B-416E-9656-2D2AAFBC058B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: B21A98A2-C953-4C73-84CF-CFFB6F712200\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 51667E99-7686-4496-B23D-6DA54F7E37AE\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 0921F87B-BF55-4B78-B8B0-E023B4D7A2E2\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F9E3251-029C-457A-9ADA-7F21A440AAF9\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 41EBEA2D-1A4B-4654-8A41-186639B9AB9F\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 6B93AEC2-910C-4064-80FB-91AED487AB97\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 83049379-23DE-4CB0-8299-7137BB836D48\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: B08FCA1F-F454-4C34-AC01-42F16354BCBC\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 12E5D72C-25A6-4ED6-8384-7C291EC43768\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 4F287859-5A00-47EF-AC91-8A2629F8C6A1\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3744F705-2C4A-406C-AA96-EB1B557A84EF\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F77D500-457E-4A96-9CE1-1DEF3FC7033B\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 455C2228-0D6F-4B62-8336-4BAA24C1A46E\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 7E37E058-670C-4ED6-B7BE-DC00F309D9FF\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 0F517C3D-162C-4C5E-AE18-544B201C9BC0\n",
            "Response Status: 404 - Not Found\n",
            "Download failed\n",
            "Download of ETH has been aborted\n",
            "Downloading solana market history data for 2020\n",
            "Using apikey: 70E10174-E29D-449F-9F2E-6E8362931DD9\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 27E5E40C-7A6B-45EB-A5C8-8311B049A741\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 8F6252DE-0AD7-478F-91C7-141141E8BE8B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 3B49210E-100B-4F8D-9011-2BA5D38274BA\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: BF6BF46F-B44B-416E-9656-2D2AAFBC058B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: B21A98A2-C953-4C73-84CF-CFFB6F712200\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 51667E99-7686-4496-B23D-6DA54F7E37AE\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 0921F87B-BF55-4B78-B8B0-E023B4D7A2E2\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F9E3251-029C-457A-9ADA-7F21A440AAF9\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 41EBEA2D-1A4B-4654-8A41-186639B9AB9F\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 6B93AEC2-910C-4064-80FB-91AED487AB97\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 83049379-23DE-4CB0-8299-7137BB836D48\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: B08FCA1F-F454-4C34-AC01-42F16354BCBC\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 12E5D72C-25A6-4ED6-8384-7C291EC43768\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 4F287859-5A00-47EF-AC91-8A2629F8C6A1\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3744F705-2C4A-406C-AA96-EB1B557A84EF\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F77D500-457E-4A96-9CE1-1DEF3FC7033B\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 455C2228-0D6F-4B62-8336-4BAA24C1A46E\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 7E37E058-670C-4ED6-B7BE-DC00F309D9FF\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 0F517C3D-162C-4C5E-AE18-544B201C9BC0\n",
            "Response Status: 404 - Not Found\n",
            "Download failed\n",
            "Download of SOL has been aborted\n",
            "Downloading ada market history data for 2017\n",
            "Using apikey: 70E10174-E29D-449F-9F2E-6E8362931DD9\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 27E5E40C-7A6B-45EB-A5C8-8311B049A741\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 8F6252DE-0AD7-478F-91C7-141141E8BE8B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 3B49210E-100B-4F8D-9011-2BA5D38274BA\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: BF6BF46F-B44B-416E-9656-2D2AAFBC058B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: B21A98A2-C953-4C73-84CF-CFFB6F712200\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 51667E99-7686-4496-B23D-6DA54F7E37AE\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 0921F87B-BF55-4B78-B8B0-E023B4D7A2E2\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F9E3251-029C-457A-9ADA-7F21A440AAF9\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 41EBEA2D-1A4B-4654-8A41-186639B9AB9F\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 6B93AEC2-910C-4064-80FB-91AED487AB97\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 83049379-23DE-4CB0-8299-7137BB836D48\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: B08FCA1F-F454-4C34-AC01-42F16354BCBC\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 12E5D72C-25A6-4ED6-8384-7C291EC43768\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 4F287859-5A00-47EF-AC91-8A2629F8C6A1\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3744F705-2C4A-406C-AA96-EB1B557A84EF\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F77D500-457E-4A96-9CE1-1DEF3FC7033B\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 455C2228-0D6F-4B62-8336-4BAA24C1A46E\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 7E37E058-670C-4ED6-B7BE-DC00F309D9FF\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 0F517C3D-162C-4C5E-AE18-544B201C9BC0\n",
            "Response Status: 404 - Not Found\n",
            "Download failed\n",
            "Download of ADA has been aborted\n",
            "Downloading bnb market history data for 2019\n",
            "Using apikey: 70E10174-E29D-449F-9F2E-6E8362931DD9\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 27E5E40C-7A6B-45EB-A5C8-8311B049A741\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 8F6252DE-0AD7-478F-91C7-141141E8BE8B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 3B49210E-100B-4F8D-9011-2BA5D38274BA\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: BF6BF46F-B44B-416E-9656-2D2AAFBC058B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: B21A98A2-C953-4C73-84CF-CFFB6F712200\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 51667E99-7686-4496-B23D-6DA54F7E37AE\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 0921F87B-BF55-4B78-B8B0-E023B4D7A2E2\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F9E3251-029C-457A-9ADA-7F21A440AAF9\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 41EBEA2D-1A4B-4654-8A41-186639B9AB9F\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 6B93AEC2-910C-4064-80FB-91AED487AB97\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 83049379-23DE-4CB0-8299-7137BB836D48\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: B08FCA1F-F454-4C34-AC01-42F16354BCBC\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 12E5D72C-25A6-4ED6-8384-7C291EC43768\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 4F287859-5A00-47EF-AC91-8A2629F8C6A1\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3744F705-2C4A-406C-AA96-EB1B557A84EF\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F77D500-457E-4A96-9CE1-1DEF3FC7033B\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 455C2228-0D6F-4B62-8336-4BAA24C1A46E\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 7E37E058-670C-4ED6-B7BE-DC00F309D9FF\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 0F517C3D-162C-4C5E-AE18-544B201C9BC0\n",
            "Response Status: 404 - Not Found\n",
            "Download failed\n",
            "Download of BNB has been aborted\n",
            "Downloading xrp market history data for 2019\n",
            "Using apikey: 70E10174-E29D-449F-9F2E-6E8362931DD9\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 27E5E40C-7A6B-45EB-A5C8-8311B049A741\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 8F6252DE-0AD7-478F-91C7-141141E8BE8B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 3B49210E-100B-4F8D-9011-2BA5D38274BA\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: BF6BF46F-B44B-416E-9656-2D2AAFBC058B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: B21A98A2-C953-4C73-84CF-CFFB6F712200\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 51667E99-7686-4496-B23D-6DA54F7E37AE\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 0921F87B-BF55-4B78-B8B0-E023B4D7A2E2\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F9E3251-029C-457A-9ADA-7F21A440AAF9\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 41EBEA2D-1A4B-4654-8A41-186639B9AB9F\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 6B93AEC2-910C-4064-80FB-91AED487AB97\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 83049379-23DE-4CB0-8299-7137BB836D48\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: B08FCA1F-F454-4C34-AC01-42F16354BCBC\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 12E5D72C-25A6-4ED6-8384-7C291EC43768\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 4F287859-5A00-47EF-AC91-8A2629F8C6A1\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3744F705-2C4A-406C-AA96-EB1B557A84EF\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F77D500-457E-4A96-9CE1-1DEF3FC7033B\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 455C2228-0D6F-4B62-8336-4BAA24C1A46E\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 7E37E058-670C-4ED6-B7BE-DC00F309D9FF\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 0F517C3D-162C-4C5E-AE18-544B201C9BC0\n",
            "Response Status: 404 - Not Found\n",
            "Download failed\n",
            "Download of XRP has been aborted\n",
            "Downloading doge market history data for 2020\n",
            "Using apikey: 70E10174-E29D-449F-9F2E-6E8362931DD9\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 27E5E40C-7A6B-45EB-A5C8-8311B049A741\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 8F6252DE-0AD7-478F-91C7-141141E8BE8B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 3B49210E-100B-4F8D-9011-2BA5D38274BA\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: BF6BF46F-B44B-416E-9656-2D2AAFBC058B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: B21A98A2-C953-4C73-84CF-CFFB6F712200\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 51667E99-7686-4496-B23D-6DA54F7E37AE\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 0921F87B-BF55-4B78-B8B0-E023B4D7A2E2\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F9E3251-029C-457A-9ADA-7F21A440AAF9\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 41EBEA2D-1A4B-4654-8A41-186639B9AB9F\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 6B93AEC2-910C-4064-80FB-91AED487AB97\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 83049379-23DE-4CB0-8299-7137BB836D48\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: B08FCA1F-F454-4C34-AC01-42F16354BCBC\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 12E5D72C-25A6-4ED6-8384-7C291EC43768\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 4F287859-5A00-47EF-AC91-8A2629F8C6A1\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3744F705-2C4A-406C-AA96-EB1B557A84EF\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F77D500-457E-4A96-9CE1-1DEF3FC7033B\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 455C2228-0D6F-4B62-8336-4BAA24C1A46E\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 7E37E058-670C-4ED6-B7BE-DC00F309D9FF\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 0F517C3D-162C-4C5E-AE18-544B201C9BC0\n",
            "Response Status: 404 - Not Found\n",
            "Download failed\n",
            "Download of DOGE has been aborted\n",
            "Downloading polygon market history data for 2020\n",
            "Using apikey: 70E10174-E29D-449F-9F2E-6E8362931DD9\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 27E5E40C-7A6B-45EB-A5C8-8311B049A741\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 8F6252DE-0AD7-478F-91C7-141141E8BE8B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 3B49210E-100B-4F8D-9011-2BA5D38274BA\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: BF6BF46F-B44B-416E-9656-2D2AAFBC058B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: B21A98A2-C953-4C73-84CF-CFFB6F712200\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 51667E99-7686-4496-B23D-6DA54F7E37AE\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 0921F87B-BF55-4B78-B8B0-E023B4D7A2E2\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F9E3251-029C-457A-9ADA-7F21A440AAF9\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 41EBEA2D-1A4B-4654-8A41-186639B9AB9F\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 6B93AEC2-910C-4064-80FB-91AED487AB97\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 83049379-23DE-4CB0-8299-7137BB836D48\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: B08FCA1F-F454-4C34-AC01-42F16354BCBC\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 12E5D72C-25A6-4ED6-8384-7C291EC43768\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 4F287859-5A00-47EF-AC91-8A2629F8C6A1\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3744F705-2C4A-406C-AA96-EB1B557A84EF\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F77D500-457E-4A96-9CE1-1DEF3FC7033B\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 455C2228-0D6F-4B62-8336-4BAA24C1A46E\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 7E37E058-670C-4ED6-B7BE-DC00F309D9FF\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 0F517C3D-162C-4C5E-AE18-544B201C9BC0\n",
            "Response Status: 404 - Not Found\n",
            "Download failed\n",
            "Download of MATIC has been aborted\n",
            "Downloading tron market history data for 2018\n",
            "Using apikey: 70E10174-E29D-449F-9F2E-6E8362931DD9\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 27E5E40C-7A6B-45EB-A5C8-8311B049A741\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 8F6252DE-0AD7-478F-91C7-141141E8BE8B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 3B49210E-100B-4F8D-9011-2BA5D38274BA\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: BF6BF46F-B44B-416E-9656-2D2AAFBC058B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: B21A98A2-C953-4C73-84CF-CFFB6F712200\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 51667E99-7686-4496-B23D-6DA54F7E37AE\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 0921F87B-BF55-4B78-B8B0-E023B4D7A2E2\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F9E3251-029C-457A-9ADA-7F21A440AAF9\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 41EBEA2D-1A4B-4654-8A41-186639B9AB9F\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 6B93AEC2-910C-4064-80FB-91AED487AB97\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 83049379-23DE-4CB0-8299-7137BB836D48\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: B08FCA1F-F454-4C34-AC01-42F16354BCBC\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 12E5D72C-25A6-4ED6-8384-7C291EC43768\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 4F287859-5A00-47EF-AC91-8A2629F8C6A1\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3744F705-2C4A-406C-AA96-EB1B557A84EF\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F77D500-457E-4A96-9CE1-1DEF3FC7033B\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 455C2228-0D6F-4B62-8336-4BAA24C1A46E\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 7E37E058-670C-4ED6-B7BE-DC00F309D9FF\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 0F517C3D-162C-4C5E-AE18-544B201C9BC0\n",
            "Response Status: 404 - Not Found\n",
            "Download failed\n",
            "Download of TRON has been aborted\n",
            "Downloading litecoin market history data for 2018\n",
            "Using apikey: 70E10174-E29D-449F-9F2E-6E8362931DD9\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 27E5E40C-7A6B-45EB-A5C8-8311B049A741\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 8F6252DE-0AD7-478F-91C7-141141E8BE8B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 3B49210E-100B-4F8D-9011-2BA5D38274BA\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: BF6BF46F-B44B-416E-9656-2D2AAFBC058B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: B21A98A2-C953-4C73-84CF-CFFB6F712200\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 51667E99-7686-4496-B23D-6DA54F7E37AE\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 0921F87B-BF55-4B78-B8B0-E023B4D7A2E2\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F9E3251-029C-457A-9ADA-7F21A440AAF9\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 41EBEA2D-1A4B-4654-8A41-186639B9AB9F\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 6B93AEC2-910C-4064-80FB-91AED487AB97\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 83049379-23DE-4CB0-8299-7137BB836D48\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: B08FCA1F-F454-4C34-AC01-42F16354BCBC\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 12E5D72C-25A6-4ED6-8384-7C291EC43768\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 4F287859-5A00-47EF-AC91-8A2629F8C6A1\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3744F705-2C4A-406C-AA96-EB1B557A84EF\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F77D500-457E-4A96-9CE1-1DEF3FC7033B\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 455C2228-0D6F-4B62-8336-4BAA24C1A46E\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 7E37E058-670C-4ED6-B7BE-DC00F309D9FF\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 0F517C3D-162C-4C5E-AE18-544B201C9BC0\n",
            "Response Status: 404 - Not Found\n",
            "Download failed\n",
            "Download of LTC has been aborted\n",
            "Downloading polkadot market history data for 2021\n",
            "Using apikey: 70E10174-E29D-449F-9F2E-6E8362931DD9\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 27E5E40C-7A6B-45EB-A5C8-8311B049A741\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 8F6252DE-0AD7-478F-91C7-141141E8BE8B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 3B49210E-100B-4F8D-9011-2BA5D38274BA\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: BF6BF46F-B44B-416E-9656-2D2AAFBC058B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: B21A98A2-C953-4C73-84CF-CFFB6F712200\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 51667E99-7686-4496-B23D-6DA54F7E37AE\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 0921F87B-BF55-4B78-B8B0-E023B4D7A2E2\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F9E3251-029C-457A-9ADA-7F21A440AAF9\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 41EBEA2D-1A4B-4654-8A41-186639B9AB9F\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 6B93AEC2-910C-4064-80FB-91AED487AB97\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 83049379-23DE-4CB0-8299-7137BB836D48\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: B08FCA1F-F454-4C34-AC01-42F16354BCBC\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 12E5D72C-25A6-4ED6-8384-7C291EC43768\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 4F287859-5A00-47EF-AC91-8A2629F8C6A1\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3744F705-2C4A-406C-AA96-EB1B557A84EF\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F77D500-457E-4A96-9CE1-1DEF3FC7033B\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 455C2228-0D6F-4B62-8336-4BAA24C1A46E\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 7E37E058-670C-4ED6-B7BE-DC00F309D9FF\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 0F517C3D-162C-4C5E-AE18-544B201C9BC0\n",
            "Response Status: 404 - Not Found\n",
            "Download failed\n",
            "Download of DOT has been aborted\n",
            "Downloading avalanche market history data for 2021\n",
            "Using apikey: 70E10174-E29D-449F-9F2E-6E8362931DD9\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 27E5E40C-7A6B-45EB-A5C8-8311B049A741\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 8F6252DE-0AD7-478F-91C7-141141E8BE8B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 3B49210E-100B-4F8D-9011-2BA5D38274BA\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: BF6BF46F-B44B-416E-9656-2D2AAFBC058B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: B21A98A2-C953-4C73-84CF-CFFB6F712200\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 51667E99-7686-4496-B23D-6DA54F7E37AE\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 0921F87B-BF55-4B78-B8B0-E023B4D7A2E2\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F9E3251-029C-457A-9ADA-7F21A440AAF9\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 41EBEA2D-1A4B-4654-8A41-186639B9AB9F\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 6B93AEC2-910C-4064-80FB-91AED487AB97\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 83049379-23DE-4CB0-8299-7137BB836D48\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: B08FCA1F-F454-4C34-AC01-42F16354BCBC\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 12E5D72C-25A6-4ED6-8384-7C291EC43768\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 4F287859-5A00-47EF-AC91-8A2629F8C6A1\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3744F705-2C4A-406C-AA96-EB1B557A84EF\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F77D500-457E-4A96-9CE1-1DEF3FC7033B\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 455C2228-0D6F-4B62-8336-4BAA24C1A46E\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 7E37E058-670C-4ED6-B7BE-DC00F309D9FF\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 0F517C3D-162C-4C5E-AE18-544B201C9BC0\n",
            "Response Status: 404 - Not Found\n",
            "Download failed\n",
            "Download of AVAX has been aborted\n",
            "Downloading monero market history data for 2018\n",
            "Using apikey: 70E10174-E29D-449F-9F2E-6E8362931DD9\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 27E5E40C-7A6B-45EB-A5C8-8311B049A741\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 8F6252DE-0AD7-478F-91C7-141141E8BE8B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 3B49210E-100B-4F8D-9011-2BA5D38274BA\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: BF6BF46F-B44B-416E-9656-2D2AAFBC058B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: B21A98A2-C953-4C73-84CF-CFFB6F712200\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 51667E99-7686-4496-B23D-6DA54F7E37AE\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 0921F87B-BF55-4B78-B8B0-E023B4D7A2E2\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F9E3251-029C-457A-9ADA-7F21A440AAF9\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 41EBEA2D-1A4B-4654-8A41-186639B9AB9F\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 6B93AEC2-910C-4064-80FB-91AED487AB97\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 83049379-23DE-4CB0-8299-7137BB836D48\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: B08FCA1F-F454-4C34-AC01-42F16354BCBC\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 12E5D72C-25A6-4ED6-8384-7C291EC43768\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 4F287859-5A00-47EF-AC91-8A2629F8C6A1\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3744F705-2C4A-406C-AA96-EB1B557A84EF\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F77D500-457E-4A96-9CE1-1DEF3FC7033B\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 455C2228-0D6F-4B62-8336-4BAA24C1A46E\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 7E37E058-670C-4ED6-B7BE-DC00F309D9FF\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 0F517C3D-162C-4C5E-AE18-544B201C9BC0\n",
            "Response Status: 404 - Not Found\n",
            "Download failed\n",
            "Download of XMR has been aborted\n",
            "Downloading basic authentication token market history data for 2018\n",
            "Using apikey: 70E10174-E29D-449F-9F2E-6E8362931DD9\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 27E5E40C-7A6B-45EB-A5C8-8311B049A741\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 8F6252DE-0AD7-478F-91C7-141141E8BE8B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 3B49210E-100B-4F8D-9011-2BA5D38274BA\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: BF6BF46F-B44B-416E-9656-2D2AAFBC058B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: B21A98A2-C953-4C73-84CF-CFFB6F712200\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 51667E99-7686-4496-B23D-6DA54F7E37AE\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 0921F87B-BF55-4B78-B8B0-E023B4D7A2E2\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F9E3251-029C-457A-9ADA-7F21A440AAF9\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 41EBEA2D-1A4B-4654-8A41-186639B9AB9F\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 6B93AEC2-910C-4064-80FB-91AED487AB97\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 83049379-23DE-4CB0-8299-7137BB836D48\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: B08FCA1F-F454-4C34-AC01-42F16354BCBC\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 12E5D72C-25A6-4ED6-8384-7C291EC43768\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 4F287859-5A00-47EF-AC91-8A2629F8C6A1\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3744F705-2C4A-406C-AA96-EB1B557A84EF\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F77D500-457E-4A96-9CE1-1DEF3FC7033B\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 455C2228-0D6F-4B62-8336-4BAA24C1A46E\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 7E37E058-670C-4ED6-B7BE-DC00F309D9FF\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 0F517C3D-162C-4C5E-AE18-544B201C9BC0\n",
            "Response Status: 404 - Not Found\n",
            "Download failed\n",
            "Download of BAT has been aborted\n",
            "Downloading loopring market history data for 2018\n",
            "Using apikey: 70E10174-E29D-449F-9F2E-6E8362931DD9\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 27E5E40C-7A6B-45EB-A5C8-8311B049A741\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 8F6252DE-0AD7-478F-91C7-141141E8BE8B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 3B49210E-100B-4F8D-9011-2BA5D38274BA\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: BF6BF46F-B44B-416E-9656-2D2AAFBC058B\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: B21A98A2-C953-4C73-84CF-CFFB6F712200\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 51667E99-7686-4496-B23D-6DA54F7E37AE\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 0921F87B-BF55-4B78-B8B0-E023B4D7A2E2\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F9E3251-029C-457A-9ADA-7F21A440AAF9\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 41EBEA2D-1A4B-4654-8A41-186639B9AB9F\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 6B93AEC2-910C-4064-80FB-91AED487AB97\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 83049379-23DE-4CB0-8299-7137BB836D48\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: B08FCA1F-F454-4C34-AC01-42F16354BCBC\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 12E5D72C-25A6-4ED6-8384-7C291EC43768\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 4F287859-5A00-47EF-AC91-8A2629F8C6A1\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3744F705-2C4A-406C-AA96-EB1B557A84EF\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 3F77D500-457E-4A96-9CE1-1DEF3FC7033B\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 455C2228-0D6F-4B62-8336-4BAA24C1A46E\n",
            "Response Status: 401 - Unauthorized\n",
            "Using apikey: 7E37E058-670C-4ED6-B7BE-DC00F309D9FF\n",
            "Response Status: 404 - Not Found\n",
            "Using apikey: 0F517C3D-162C-4C5E-AE18-544B201C9BC0\n",
            "Response Status: 404 - Not Found\n",
            "Download failed\n",
            "Download of LRC has been aborted\n"
          ]
        }
      ]
    }
  ]
}